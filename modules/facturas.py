import os
import time
import datetime
import pandas as pd
from lxml import etree
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.common.keys import Keys
from selenium.common.exceptions import TimeoutException
#from modules.helpers import 
import numpy as np
import concurrent.futures  # Agregar para procesamiento paralelo
import yaml
from pathlib import Path
import shutil
from PyPDF2 import PdfReader
import re


class FACTURAS:
    def __init__(self, working_folder, data_access):
        self.working_folder = working_folder
        self.data_access = data_access
        
    def cargar_facturas(self, facturas):
        facturas_folder = os.path.join(self.working_folder, "Facturas")
        os.makedirs(facturas_folder, exist_ok=True)
        xlsx_database = os.path.join(facturas_folder, 'xmls_extraidos.xlsx')
        self.smart_xml_extraction(xlsx_database)   
        
        preffix = os.path.basename(facturas_folder)
        # DataFrame general vac√≠o
        df_general = pd.DataFrame()

        # Iterar sobre los paquetes en PAQS_IMSS
        for paq_name, paq_info in self.data_access.get(facturas, {}).items():
            file_path = paq_info.get("file_path")
            sheet = paq_info.get("sheet")
            rows = paq_info.get("rows", [])

            print(f"\nüîç Procesando {paq_name}")

            # 1. Intentar cargar archivo
            if not os.path.exists(file_path):
                print(f"‚ö†Ô∏è Archivo no encontrado: {file_path}")
                continue
            print(f"‚úÖ Archivo encontrado: {file_path}")

            try:
                # 2. Intentar cargar hoja con columnas definidas
                df = pd.read_excel(file_path, sheet_name=sheet, usecols=rows)
                print(f"‚úÖ Hoja '{sheet}' cargada con columnas {rows}")

                # Concatenar a df_general
                df_general = pd.concat([df_general, df], ignore_index=True)

            except ValueError as e:
                print(f"‚ö†Ô∏è Problema con la hoja o columnas: {e}")
                continue

        # Guardar resultado en carpeta local
        if not df_general.empty:
            today = datetime.datetime.today().strftime("%Y-%m-%d-%H")  # ‚úÖ Formato de fecha corregido
            output_file = os.path.join(facturas_folder, f"{today}h_{facturas}.xlsx")  # ‚úÖ Usar carpeta local
            df_xmls = pd.read_excel(xlsx_database)
            print(f"üìä Filas en df_xmls antes de limpiar: {df_xmls.shape[0]}")

            # Verificar duplicados por Folio
            duplicados = df_xmls['Folio'].duplicated().sum()
            if duplicados > 0:
                print(f"‚ö†Ô∏è Se encontraron {duplicados} folios duplicados en df_xmls")
                
                # Opci√≥n A: Eliminar duplicados manteniendo el primero
                df_xmls = df_xmls.drop_duplicates(subset=['Folio'], keep='first')
                print(f"‚úÖ Duplicados eliminados. Filas restantes: {df_xmls.shape[0]}")
            print(f"Filas antes de la fusi√≥n con el XML {df_general.shape[0]}")
            print(df_general.head(),df_xmls.head())
            df_general = pd.merge(df_general, df_xmls, how='left', left_on='Factura', right_on='Folio')
            print(f"print filas despu√©s de la fusi√≥n con el XML {df_general.shape[0]}")
            print("\n‚úÖ DataFrame fusionado con informaci√≥n XML con √©xito.")
            # --- Cargar estatus SAT y eliminar Cancelados ---
            invoice_to_check = os.path.join(self.working_folder, "Estatus SAT", "estatus_facturas.xlsx")
            if os.path.isfile(invoice_to_check):
                df_status_SAT = pd.read_excel(invoice_to_check)

                # Asegurarnos de que las columnas existan
                if {'uuid', 'estado'}.issubset(df_status_SAT.columns):
                    # Lista de UUID cancelados
                    uuid_list = df_status_SAT.loc[df_status_SAT['estado'] == 'Cancelado', 'uuid'].astype(str).tolist()
                    print(f"‚ö†Ô∏è  {len(uuid_list)} UUIDs marcados como Cancelado en SAT")

                    # Quitar de invoice_df los UUID que est√°n en esa lista
                    # Marcar como Cancelado en invoice_df
                    mask = df_general['UUID'].astype(str).isin(uuid_list)
                    df_general.loc[mask, 'UUID Descripci√≥n'] = 'Cancelado'

                    print(f"üìù {mask.sum()} facturas actualizadas como Cancelado")

                    
                else:
                    print("‚ö†Ô∏è Archivo estatus_facturas.xlsx no tiene columnas esperadas: 'uuid', 'estado'")
            else:
                print("‚ÑπÔ∏è No existe estatus_facturas.xlsx, no se filtraron cancelados")

            try:
                df_general.to_excel(output_file, index=False)
                print(f"\nüíæ Archivo guardado en {output_file}")
                print(f"üìä Total de filas procesadas: {len(df_general)}")
                return True
            except PermissionError as e:
                print(f"‚ùå Error de permisos: {e}")
                print(f"üîÑ Intentando guardar en carpeta alternativa...")
                
                # Fallback: guardar en carpeta temporal
                import tempfile
                temp_dir = tempfile.gettempdir()
                fallback_file = os.path.join(temp_dir, f"{today}_facturas.xlsx")
                df_general.to_excel(fallback_file, index=False)
                print(f"üíæ Archivo guardado en ubicaci√≥n temporal: {fallback_file}")

                return False

        else:
            print("\n‚ö†Ô∏è No se gener√≥ DataFrame, revisar configuraci√≥n.")        
        #self.check_invoice_status(facturas)

        
    def smart_xml_extraction(self, xlsx_database):
        print(("Extrayendo la informaci√≥n de los XMLs..."))
        invoice_paths = []
        for path in self.data_access['facturas_path']:
            if os.path.exists(path):
                invoice_paths.append(path)

        # Cargar base existente si existe
        if os.path.exists(xlsx_database):
            df_database = pd.read_excel(xlsx_database)
            existing_uuids = set(df_database['UUID'].dropna())  # Set de UUIDs existentes para check r√°pido
            existing_folios_files = set(zip(df_database['Folio'], df_database['Archivo']))  # Para check alternativo
        else:
            df_database = pd.DataFrame(columns=[
                'UUID', 'Folio', 'Fecha', 'Nombre', 'Rfc',
                'Descripcion', 'Cantidad', 'Importe', 'Archivo'
            ])
            existing_uuids = set()
            existing_folios_files = set()

        data = []

        # Funci√≥n para procesar un archivo XML (para paralelizar)
        def process_xml_file(full_path, file):
            try:
                tree = etree.parse(full_path)
                root_element = tree.getroot()

                # Detectar namespace
                ns = None
                for ns_url in root_element.nsmap.values():
                    if "cfd/3" in ns_url:
                        ns = {
                            "cfdi": "http://www.sat.gob.mx/cfd/3",
                            "tfd": "http://www.sat.gob.mx/TimbreFiscalDigital"
                        }
                        break
                    elif "cfd/4" in ns_url:
                        ns = {
                            "cfdi": "http://www.sat.gob.mx/cfd/4",
                            "tfd": "http://www.sat.gob.mx/TimbreFiscalDigital"
                        }
                        break
                if ns is None:
                    return []  # No procesar si no hay namespace v√°lido

                # Extraer Folio y Serie
                folio = root_element.get('Folio')
                serie = root_element.get('Serie')
                folio_completo = f"{serie}-{folio}" if serie and folio else folio or serie or ""

                # Extraer Fecha
                fecha = root_element.get('Fecha')

                # Extraer UUID
                uuid = None
                complemento = root_element.find('./cfdi:Complemento', ns)
                if complemento is not None:
                    timbre = complemento.find('./tfd:TimbreFiscalDigital', ns)
                    if timbre is not None:
                        uuid = timbre.get('UUID')

                # Check si ya existe
                if uuid and uuid in existing_uuids:
                    return []  # Omitir
                elif (folio_completo, file) in existing_folios_files:
                    return []  # Omitir

                # Extraer receptor
                rec = root_element.find('./cfdi:Receptor', ns)
                if rec is None:
                    return []
                nombre = rec.get('Nombre')
                rfc = rec.get('Rfc')

                # Extraer conceptos
                conceptos_data = []
                for concepto in root_element.findall('./cfdi:Conceptos/cfdi:Concepto', ns):
                    descripcion = concepto.get('Descripcion')
                    cantidad = concepto.get('Cantidad')
                    importe = concepto.get('Importe')

                    conceptos_data.append([
                        uuid,
                        folio_completo,
                        fecha,
                        nombre,
                        rfc,
                        descripcion,
                        cantidad,
                        importe,
                        file
                    ])

                return conceptos_data

            except Exception as e:
                print(f"[ERROR] Al procesar {file}: {e}")
                return []

        # Recopilar todos los archivos a procesar
        xml_files = []
        for folder in invoice_paths:
            print(f"\nExplorando carpeta: {folder}")
            for root_dir, dirs, files in os.walk(folder):
                for file in files:
                    if file.endswith('.xml'):
                        full_path = os.path.join(root_dir, file)
                        xml_files.append((full_path, file))

        # Procesar en paralelo usando ThreadPoolExecutor (para I/O bound)
        with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:  # Ajusta max_workers seg√∫n tu CPU
            futures = [executor.submit(process_xml_file, full_path, file) for full_path, file in xml_files]
            for future in concurrent.futures.as_completed(futures):
                result = future.result()
                if result:
                    data.extend(result)

        # Si hay nuevos registros, agregarlos y guardar
        if data:
            df_nuevos = pd.DataFrame(data, columns=[
                'UUID', 'Folio', 'Fecha', 'Nombre', 'Rfc',
                'Descripcion', 'Cantidad', 'Importe', 'Archivo'
            ])
            df_database = pd.concat([df_database, df_nuevos], ignore_index=True)
            df_database[['Cantidad', 'Importe']] = df_database[['Cantidad', 'Importe']].astype(float)
            df_database.to_excel(xlsx_database, engine='openpyxl', index=False)
            print(f"\n‚úÖ Se agregaron {len(df_nuevos)} nuevos registros a {xlsx_database}")
        else:
            print("\n‚úîÔ∏è No se encontraron nuevos XMLs para agregar.")


    # ==== 
    # SECCI√ìN PARA CONFIRMAR EL ESTATUS DE LAS FACTURAS
    # ====

    def check_invoice_status(self, facturas):
        print("Ingresando a la secci√≥n para segregar los PDF's")

        # --- Folders ---
        invoice_to_check = os.path.join(self.working_folder, "Estatus SAT")
        invoice_temporal_files = os.path.join(invoice_to_check, "PDFs")
        os.makedirs(invoice_temporal_files, exist_ok=True)

        # --- Read Excel list of folios ---
        xlsx_database = os.path.join(invoice_to_check, "Estatus_SAT_Download.xlsx")
        if not os.path.isfile(xlsx_database):
            print(f"‚ùå No existe el Excel de folios: {xlsx_database}")
            return

        pdf_files_list = pd.read_excel(xlsx_database)
        if pdf_files_list.empty or "Folio" not in pdf_files_list.columns:
            print("‚ùå No folios encontrados en el archivo Excel.")
            return

        print(pdf_files_list.head())

        # --- Load YAML (ya est√° en la clase) -> usar carpeta del Excel como ra√≠z de b√∫squeda ---
        paqs = self.data_access.get(facturas, {})
        base_dirs = []

        for name, cfg in paqs.items():
            excel_path = Path(cfg["file_path"])
            folder = excel_path.parent  # carpeta donde vive el Excel
            base_dirs.append(folder)

        # Deduplicar y normalizar
        base_dirs = list(dict.fromkeys([d.resolve() for d in base_dirs]))
        print("\nüìÇ Carpetas base a escanear:")
        for d in base_dirs:
            print(f"  - {d}  (exists: {d.exists()})")

        # --- Indexar TODOS los PDFs de forma recursiva (una sola pasada) ---
        pdf_index = []  # lista de tuplas: (nombre_base_lower, ruta_abs_str)
        total_indexed = 0
        for d in base_dirs:
            if not d.exists():
                print(f"‚ö†Ô∏è  Carpeta inexistente: {d}")
                continue
            count = 0
            # rglob es recursivo: busca en subcarpetas (ej. "08 Agosto\...")
            for pdf in d.rglob("*.pdf"):
                pdf_index.append((pdf.name.lower(), str(pdf)))
                count += 1
            total_indexed += count
            print(f"   ‚Üí {count} PDFs indexados bajo {d}")

        print(f"üîé Total PDFs indexados: {total_indexed}")

        if total_indexed == 0:
            print("‚ùå No se index√≥ ning√∫n PDF. Revisa rutas/permiso de Dropbox/drive.")
            return

        # (Debug opcional) mostrar algunos nombres para validar
        print("üß™ Ejemplos de PDFs indexados:")
        for name, path in pdf_index[:min(5, len(pdf_index))]:
            print(f"   - {name}")

        # --- Buscar por prefijo y copiar ---
        expected = len(pdf_files_list)
        found = 0
        not_found = []
        duplicates = {}

        for raw_folio in pdf_files_list["Folio"].astype(str):
            folio = raw_folio.strip().lower()  # normalizar
            matched_paths = [p for (name, p) in pdf_index if name.startswith(folio)]

            if matched_paths:
                # Si hay m√°s de uno, reportar duplicados y tomar el primero
                if len(matched_paths) > 1:
                    duplicates[raw_folio] = matched_paths[:5]  # guarda hasta 5 para no saturar consola

                src = matched_paths[0]
                dst = os.path.join(invoice_temporal_files, f"{raw_folio}.pdf")
                try:
                    shutil.copy2(src, dst)
                    print(f"‚úî Copiado: {raw_folio} -> {dst}")
                    found += 1
                except Exception as e:
                    print(f"‚ùå Error copiando {src} -> {dst}: {e}")
            else:
                not_found.append(raw_folio)

        # --- Summary ---
        print("\n--- Resumen ---")
        print(f"Expected: {expected}")
        print(f"Found:    {found}")
        if duplicates:
            print(f"‚ö†Ô∏è Duplicados detectados ({len(duplicates)} folios). Se us√≥ el primero encontrado:")
            for fol, paths in duplicates.items():
                print(f"   ¬∑ {fol}:")
                for p in paths:
                    print(f"      - {p}")
        if not_found:
            print(f"Not found ({len(not_found)}): {not_found}")
        self.extract_estatus_pdf()

    def extract_estatus_pdf(self):
        acuses_sat = os.path.join(self.working_folder, "Estatus SAT", "Comprobantes SAT")
        output_file = os.path.join(self.working_folder, "Estatus SAT", "estatus_facturas.xlsx")

        list_pdf_files = [f for f in os.listdir(acuses_sat) if f.lower().endswith(".pdf")]

        if not list_pdf_files:
            print("‚ùå No se encontraron PDFs en:", acuses_sat)
            return

        results = []

        for pdf_file in list_pdf_files:
            pdf_path = os.path.join(acuses_sat, pdf_file)
            try:
                reader = PdfReader(pdf_path)
                text = ""
                for page in reader.pages:
                    text += page.extract_text() or ""

                # Normalizar texto
                clean_text = text.replace("\n", " ").replace("\r", " ")

                # Regex tolerante: capturar entre &id= y &re=
                match = re.search(r"&id=([\s\S]+?)&re=", clean_text, re.IGNORECASE)
                uuid = None
                if match:
                    uuid = match.group(1)
                    # limpiar espacios intermedios
                    uuid = uuid.replace(" ", "").replace("\n", "").replace("\r", "")

                # Estado
                if "Cancelado" in clean_text:
                    estado = "Cancelado"
                elif "Vigente" in clean_text:
                    estado = "Vigente"
                else:
                    estado = "Desconocido"

                results.append({
                    "uuid": uuid,
                    "estado": estado,
                    "filename": os.path.basename(pdf_file)
                })

            except Exception as e:
                print(f"‚ùå Error procesando {pdf_file}: {e}")

        # Guardar resultados
        df = pd.DataFrame(results)
        df.to_excel(output_file, index=False)

        print(f"‚úî Resultados guardados en {output_file}")
        print(df.head())
if __name__ == "__main__":
    folder_root = os.getcwd()    
    working_folder = os.path.join(folder_root, "Implementaci√≥n")
    config_path = os.path.join(working_folder, "config.yaml")
    yaml_exists = os.path.exists(config_path)
    if yaml_exists:
        # Abrir y cargar el contenido YAML en un diccionario
        with open(config_path, 'r', encoding='utf-8') as f:
            data_access = yaml.safe_load(f)
        print(f"‚úÖ Archivo YAML cargado correctamente: {os.path.basename(config_path)}")
    facturas = 'PAQS_INSABI'
    # Inicializar web driver manager (sin crear el driver a√∫n)
    app = FACTURAS(working_folder, data_access)
    app.cargar_facturas(facturas)
    
